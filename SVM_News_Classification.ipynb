{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_News_Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygDrpafwrEgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "3644d71a-42d1-4e37-bc67-99e6beeb6d8a"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "import re\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "import pickle\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import logging\n",
        "from sklearn import svm\n",
        "\n",
        "\n",
        "df=pd.read_json(r\"/content/drive/My Drive/ML codes/NLP text scan/News_Category_Dataset_v2.json\",lines=True)\n",
        "\n",
        "df=df[0:5000]\n",
        "def tokenize_url(url:str):   \n",
        "    url=url.replace(\"https://www.huffingtonpost.com/entry/\",\"\")\n",
        "    url=re.sub(\"(\\W|_)+\",\" \",url)\n",
        "    return url\n",
        "\n",
        "df['tokenized_url']=df['link'].apply(lambda x:tokenize_url(x))\n",
        "\n",
        "#just the description\n",
        "df['text_desc'] = df['short_description']\n",
        "\n",
        "#description + headline\n",
        "df['text_desc_headline'] = df['short_description'] + ' '+ df['headline']\n",
        "\n",
        "#description + headline + tokenized url\n",
        "df['text_desc_headline_url'] = df['short_description'] + ' '+ df['headline']+\" \" + df['tokenized_url']\n",
        "\n",
        "def _reciprocal_rank(true_labels: list, machine_preds: list):\n",
        "    \"\"\"Compute the reciprocal rank at cutoff k\"\"\"\n",
        "    \n",
        "    # add index to list only if machine predicted label exists in true labels\n",
        "    tp_pos_list = [(idx + 1) for idx, r in enumerate(machine_preds) if r in true_labels]\n",
        "\n",
        "    rr = 0\n",
        "    if len(tp_pos_list) > 0:\n",
        "        # for RR we need position of first correct item\n",
        "        first_pos_list = tp_pos_list[0]\n",
        "        \n",
        "        # rr = 1/rank\n",
        "        rr = 1 / float(first_pos_list)\n",
        "\n",
        "    return rr\n",
        "\n",
        "def compute_mrr_at_k(items:list):\n",
        "    \"\"\"Compute the MRR (average RR) at cutoff k\"\"\"\n",
        "    rr_total = 0\n",
        "    \n",
        "    for item in items:   \n",
        "        rr_at_k = _reciprocal_rank(item[0],item[1])\n",
        "        rr_total = rr_total + rr_at_k\n",
        "        mrr = rr_total / 1/float(len(items))\n",
        "\n",
        "    return mrr\n",
        "\n",
        "def collect_preds(Y_test,Y_preds):\n",
        "    \"\"\"Collect all predictions and ground truth\"\"\"\n",
        "    \n",
        "    pred_gold_list=[[[Y_test[idx]],pred] for idx,pred in enumerate(Y_preds)]\n",
        "    return pred_gold_list\n",
        "             \n",
        "def compute_accuracy(eval_items:list):\n",
        "    correct=0\n",
        "    total=0\n",
        "    \n",
        "    for item in eval_items:\n",
        "        true_pred=item[0]\n",
        "        machine_pred=set(item[1])\n",
        "        \n",
        "        for cat in true_pred:\n",
        "            if cat in machine_pred:\n",
        "                correct+=1\n",
        "                break\n",
        "    print(\"\\n\\n\\ncorrect = \",correct)\n",
        "    accuracy=correct/float(len(eval_items))\n",
        "    return accuracy\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "def extract_features(df,field,training_data,testing_data,type=\"binary\"):\n",
        "    \"\"\"Extract features using different methods\"\"\"\n",
        "    \n",
        "    logging.info(\"Extracting features and creating vocabulary...\")\n",
        "    \n",
        "    if \"binary\" in type:\n",
        "        \n",
        "        # BINARY FEATURE REPRESENTATION\n",
        "        cv= CountVectorizer(binary=True, max_df=0.95)\n",
        "        cv.fit_transform(training_data[field].values)\n",
        "        train_feature_set=cv.transform(training_data[field].values)\n",
        "        test_feature_set=cv.transform(testing_data[field].values)\n",
        "        # print(\"\\n\\n\\n  train_feature_set = \", train_feature_set)\n",
        "        return train_feature_set,test_feature_set,cv\n",
        "  \n",
        "    elif \"counts\" in type:\n",
        "        \n",
        "        # COUNT BASED FEATURE REPRESENTATION\n",
        "        cv= CountVectorizer(binary=False, max_df=0.95)\n",
        "        cv.fit_transform(training_data[field].values)\n",
        "        \n",
        "        train_feature_set=cv.transform(training_data[field].values)\n",
        "        test_feature_set=cv.transform(testing_data[field].values)\n",
        "        \n",
        "        return train_feature_set,test_feature_set,cv\n",
        "    \n",
        "    else:    \n",
        "        \n",
        "        # TF-IDF BASED FEATURE REPRESENTATION\n",
        "        tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.95)\n",
        "        tfidf_vectorizer.fit_transform(training_data[field].values)\n",
        "        \n",
        "        train_feature_set=tfidf_vectorizer.transform(training_data[field].values)\n",
        "        test_feature_set=tfidf_vectorizer.transform(testing_data[field].values)\n",
        "        \n",
        "        return train_feature_set,test_feature_set,tfidf_vectorizer\n",
        "\n",
        "def get_top_k_predictions(model,X_test,k):\n",
        "    \n",
        "    # get probabilities instead of predicted labels, since we want to collect top 3\n",
        "    probs = model.predict_proba(X_test)\n",
        "\n",
        "    # GET TOP K PREDICTIONS BY PROB - note these are just index\n",
        "    best_n = np.argsort(probs, axis=1)[:,-k:]\n",
        "    \n",
        "    # GET CATEGORY OF PREDICTIONS\n",
        "    preds=[[model.classes_[predicted_cat] for predicted_cat in prediction] for prediction in best_n]\n",
        "    \n",
        "    preds=[ item[::-1] for item in preds]\n",
        "    \n",
        "    return preds\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_model(df,field=\"text_desc\",feature_rep=\"binary\",top_k=3):\n",
        "    \n",
        "    logging.info(\"Starting model training...\")\n",
        "    \n",
        "    # GET A TRAIN TEST SPLIT (set seed for consistent results)\n",
        "    training_data, testing_data = train_test_split(df,random_state = 200,)\n",
        "    #print(\"\\n\\n\\n training_data = \",training_data)\n",
        "    # GET LABELS\n",
        "    Y_train=training_data['category'].values\n",
        "    Y_test=testing_data['category'].values\n",
        "   \n",
        "    # GET FEATURES\n",
        "    X_train,X_test,feature_transformer=extract_features(df,field,training_data,testing_data,type=feature_rep)\n",
        "    # print(\"\\n\\n\\\\nY X train shape = \",(X_train))\n",
        "    # print(\"\\n\\n\\\\nY X test shape = \",(X_test))\n",
        "    \n",
        "    # INIT LOGISTIC REGRESSION CLASSIFIER\n",
        "    logging.info(\"Training a SVM  Model...\")\n",
        "    clf = svm.SVC(probability=True,kernel='linear') # Linear Kernel\n",
        "\n",
        "    #scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
        "    model=clf.fit(X_train, Y_train)\n",
        "    \n",
        "    \n",
        "    # GET TOP K PREDICTIONS\n",
        "    preds=get_top_k_predictions(model,X_test,top_k)\n",
        "    \n",
        "    # GET PREDICTED VALUES AND GROUND TRUTH INTO A LIST OF LISTS - for ease of evaluation\n",
        "    eval_items=collect_preds(Y_test,preds)\n",
        "    \n",
        "    # GET EVALUATION NUMBERS ON TEST SET -- HOW DID WE DO?\n",
        "    logging.info(\"Starting evaluation...\")\n",
        "    accuracy=compute_accuracy(eval_items)\n",
        "    mrr_at_k=compute_mrr_at_k(eval_items)\n",
        "    # print(\"\\n\\n\\nEVAL ITEMS = \",eval_items)\n",
        "    \n",
        "    logging.info(\"Done training and evaluation.\")\n",
        "    #s=LogisticRegression.score(Y_test, preds,y=None)\n",
        "    #print(\"\\n\\n\\ns =\",s)\n",
        "    \n",
        "    return model,feature_transformer,accuracy,mrr_at_k\n",
        "\n",
        "\n",
        "field='text_desc'\n",
        "feature_rep='binary'\n",
        "top_k=3\n",
        "\n",
        "model,transformer,accuracy,mrr_at_k=train_model(df,field=field,feature_rep=feature_rep,top_k=top_k)\n",
        "\n",
        "\n",
        "#model_path=\"/content/drive/My Drive/ML codes/NLP text scan/model.pkl\"\n",
        "#transformer_path=\"/content/drive/My Drive/ML codes/NLP text scan/transformer.pkl\"\n",
        "\n",
        "# pickle.dump(model,open(model_path, 'wb'))\n",
        "# pickle.dump(transformer,open(transformer_path,'wb'))\n",
        "\n",
        "\n",
        "# loaded_model = pickle.load(open(model_path, 'rb'))\n",
        "# loaded_transformer = pickle.load(open(transformer_path, 'rb'))\n",
        "\n",
        "# test_features=transformer.transform([\"True Thompson makes an adorable cameo in Khloe Kardashian's new makeup tutorial video\"])\n",
        "\n",
        "print(\"\\nAccuracy={0}; MRR={1}\".format(accuracy,mrr_at_k))\n",
        "# print(get_top_k_predictions(loaded_model,test_features,2))\n",
        "\n",
        "\n",
        "#print(sklearn.metrics.confusion_matr ix(test_features, pre, labels=None, sample_weight=None, normalize=None))\n",
        "#print(\"acc=\",sklearn.metrics.accuracy_score(test_features, pre, normalize=True, sample_weight=None))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-27 12:31:44,773 : INFO : Starting model training...\n",
            "2020-04-27 12:31:44,836 : INFO : Extracting features and creating vocabulary...\n",
            "2020-04-27 12:31:44,969 : INFO : Training a SVM  Model...\n",
            "2020-04-27 12:32:13,447 : INFO : Starting evaluation...\n",
            "2020-04-27 12:32:13,451 : INFO : Done training and evaluation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "correct =  939\n",
            "\n",
            "Accuracy=0.7512; MRR=0.6217333333333339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v068zSQrMpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f77224e-4a79-4686-f511-38db2a1fb1bc"
      },
      "source": [
        "test_features=transformer.transform([\"Democrats Win Special Election In Missouri District That Went Big For Trump\"])\n",
        "pre=(get_top_k_predictions(model,test_features,2))\n",
        "pre"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['POLITICS', 'MEDIA']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vP6qqZOuPpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d=pd.read_json(r\"/content/drive/My Drive/ML codes/NLP text scan/News_Category_Dataset_v2.json\",lines=True)\n",
        "\n",
        "s=d['headline']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krykVf9mvWjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc85e079-bbaf-493c-d5ab-2bf1465b2554"
      },
      "source": [
        "s[6100]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Democrats Win Special Election In Missouri District That Went Big For Trump'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY8Q4p0Yws0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e038b940-e094-4815-a794-03b946b53f00"
      },
      "source": [
        "s[9004]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Philippine Ferry Carrying 251 Capsizes In Storm'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PqYNpBsw-27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a115d81-2787-443f-8244-aee9f106586a"
      },
      "source": [
        "s[6020]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Volunteer Gymnastics Coach Charged With Child Molestation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a1iZmAPxulf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}